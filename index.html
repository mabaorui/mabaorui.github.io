<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >	
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <style type="text/css">
  @import url(http://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300,100italic,100);
    /* Color scheme stolen from Sergey Karayev */
    a {
    /*color: #b60a1c;*/
    color: #1772d0;
    /*color: #bd0a36;*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Roboto', sans-serif;
    font-size: 15px;
    font-weight: 300;
    }
    strong {
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    /*font-family: 'Avenir Next';*/
    font-size: 15px;
    font-weight: 400;
    }
    heading {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 24px;
    font-weight: 400;
    }
    papertitle {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
    font-size: 15px;
    font-weight:500;
    }
    name {
    /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
    font-family: 'Roboto', sans-serif;
    /*font-family: 'Avenir Next';*/
    font-weight: 400;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 140px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <title>Baorui Ma - Homepage</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <script src="script/functions.js"></script>
  </head>
  <body>
  <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Baorui Ma(马宝睿)</name>
          <!--<br>
          ruthfong at robots dot ox dot ac dot uk-->
        </p>
        <p>
          I am a researcher at Beijing Academy of Artificial Intelligence <a href="https://www.baai.ac.cn/english.html/">(BAAI)</a>.  I received my PhD degree from <a href="https://www.tsinghua.edu.cn/en/"> the School of Software, Tsinghua University</a>, advised by Prof. Yu-Shen Liu.

        </p> 
        <p>
          My research interests lie in the area of 3D computer vision, 3D foundation models, 3D reconstruction, multi-view 3D reconstruction and surface reconstruction from point clouds.
        </p>
        <p align=center>
          <a href="mailto:brma@baai.ac.cn">Email</a> &nbsp|&nbsp
          <!--<a href="files/.pdf">CV</a> &nbsp|&nbsp-->
          <a href="https://github.com/mabaorui">GitHub</a> &nbsp|&nbsp
          <a href="https://scholar.google.com/citations?user=rmgXhrEAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
          <a href="https://www.linkedin.com/in/%E5%AE%9D%E7%9D%BF-%E9%A9%AC-33398a227/"> LinkedIn</a>
        </p>
        </td>
        <td width="33%">
          <img src="image/mabaorui.jpg" width="250" alt="headshot">
          
        </td>
        
      </tr>
      
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <td width="100%" valign="middle">
            <heading>Research</heading>
            <p>(*: Equal Contribution, #: corresponding author)</p>
          </td>
        </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
          

          <tr onmouseout="UDiFF_stop()" onmouseover="UDiFF_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id="UDiFF" style="opacity: 0;">
                  <video width="225" muted="" autoplay="" loop="">
                    <source src="image/UDiFF_after_2.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <img src="image/UDiFF_before.png" width="225">
        
              </div>
        
              <script type="text/javascript">
                function UDiFF_start() {
                  document.getElementById('UDiFF').style.opacity = "1";
                }
                function UDiFF_stop() {
                  document.getElementById('UDiFF').style.opacity = "0";
                }
                UDiFF_stop()
              </script>
            </td>
        
            <td width="65%" valign="top">
              <a href="https://weiqi-zhang.github.io/UDiFF/">
                <papertitle>UDiFF: Generating Conditional Unsigned Distance Fields with Optimal Wavelet Diffusion
                </papertitle>
              </a>
              <br>
              <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, Weiqi Zhang*, <strong> Baorui Ma#</strong>, Kanle Shi, 
              <a href="https://yushen-liu.github.io/"> Yu-Shen Liu#</a>, <a href="https://h312h.github.io/">Zhizhong Han</a>
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b></em>, 2024
              <br>
              <a href="https://weiqi-zhang.github.io/UDiFF/">project page</a> |             
              <a href="https://arxiv.org/abs/2404.06851">arXiv</a> |
              <a href="https://github.com/weiqi-zhang/UDiFF">code</a>
        
              <p align="justify", style="font-size:13px">UDiFF is a 3D diffusion model for unsigned distance fields (UDFs) which is capable to generate textured 3D shapes with open surfaces from text conditions or unconditionally.
              </p>
            </td>
          </tr>

          <tr onmouseout="cappami_stop()" onmouseover="cappami_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id="cappami_shape" style="opacity: 0;">
                  <img src='image/cappami_before.png' width="225">
                </div>
                <img src="image/cappami_after.png" width="225">
        
              </div>
              <script type="text/javascript">
                function cappami_start() {
                  document.getElementById('cappami_shape').style.opacity = "1";
                }
                function cappami_stop() {
                  document.getElementById('cappami_shape').style.opacity = "0";
                }
                cappami_stop()
              </script>
            </td>
        
            <td width="65%" valign="top">
              <a href="https://junshengzhou.github.io/CAP-UDF/">
                <papertitle>CAP-UDF: Learning Unsigned Distance Functions Progressively from Raw Point Clouds with Consistency-Aware Field Optimization</papertitle>
              </a>
              <br>
              <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, <strong> Baorui Ma*</strong>, Shujuan Li, <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>, <a href="http://mmvc.engineering.nyu.edu/">Yi Fang</a>, <a href="https://h312h.github.io/">Zhizhong Han</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(TPAMI)</b></em>, 2024
              <br>
              <a href="https://junshengzhou.github.io/CAP-UDF/">project page</a> |             
              <a href="https://ieeexplore.ieee.org/document/10506631">IEEE Xplore</a> | <a href="https://arxiv.org/pdf/2210.02757.pdf">arXiv</a> |
              <a href="https://github.com/junshengzhou/CAP-UDF">code</a>
        
              <p align="justify", style="font-size:13px">We present CAP-UDF to represent shapes and scenes with arbitrary architecture by learning a Consistency-Aware unsigned distance function Progressively.
              </p>
            </td>
          </tr>

          <tr onmouseout="oae_stop()" onmouseover="oae_start()">
            <td width="25%">
              <div class="one">
                  <div class="two" id="oae_shape" style="opacity: 0;">
                      <video width="225" muted="" autoplay="" loop="">
                        <source src="image/3doae_after.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
                  </div>
                <img src="image/3doae_before.png" width="225">
                <td width="65%" valign="top">
                  <a href="https://junshengzhou.github.io/3D-OAE/">
                    <papertitle>3D-OAE: Occlusion Auto-Encoders for Self-Supervised Learning on Point Clouds</papertitle>
                  </a>
                  <br>
                  <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, <a href="https://scholar.google.com/citations?user=7gcGzs8AAAAJ&hl=zh-CN&oi=ao"> Xin Wen*</a>, <strong> Baorui Ma</strong>,
                  <a href="https://yushen-liu.github.io/"> Yu-Shen Liu#</a>, <a href="https://www.gaoyue.org/"> Yue Gao</a>, <a href="http://mmvc.engineering.nyu.edu/">Yi Fang</a>, <a href="https://h312h.github.io/">Zhizhong Han</a>
                  <br>
                  <em>IEEE International Conference on Robotics and Automation <b>(ICRA)</b></em>, 2024  (<strong><span style="color:#ff0000;">Oral</span></strong>)
                  <br>
                  <a href="https://junshengzhou.github.io/3D-OAE/">project page</a> |             
                  <a href="https://arxiv.org/pdf/2203.14084.pdf">arXiv</a> |
                  <a href="https://github.com/junshengzhou/3D-OAE">code</a>
        
                  <p align="justify", style="font-size:13px">We present 3D-OAE, a novel self-supervised point cloud representation learning framework which is highly efficient and can be further transferred to various downstream tasks.
                  </p>
                </td>
              </div>
              <script type="text/javascript">
                function oae_start() {
                  document.getElementById('oae_shape').style.opacity = "1";
                }
                function oae_stop() {
                  document.getElementById('oae_shape').style.opacity = "0";
                }
                oae_stop()
              </script>
            </td>


          </tr>

          <tr onmouseout="geodream_stop()" onmouseover="geodream_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id="geodream" style="opacity: 0;">
                  <video width="225" muted="" autoplay="" loop="">
                    <source src="image/GeoDream_Video_teaser.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                </div>
                <img src="image/Qualitative-Comparison.jpg" width="225">
      
              </div>

              <script type="text/javascript">
                function geodream_start() {
                  document.getElementById('geodream').style.opacity = "1";
                }
                function geodream_stop() {
                  document.getElementById('geodream').style.opacity = "0";
                }
                geodream_stop()
              </script>
            </td>
      
            <td width="65%" valign="top">
              <a href="https://mabaorui.github.io/GeoDream_page/">
                <papertitle>GeoDream: Disentangling 2D and Geometric Priors for High-Fidelity and Consistent 3D Generation
                </papertitle>
              </a>
              <br>
                <strong> Baorui Ma*#</strong>, <a href="https://github.com/Bitterdhg/"> Haoge Deng*</a>, <a href="https://junshengzhou.github.io/"> Junsheng Zhou </a>, 
                <a href="https://yushen-liu.github.io/"> Yu-Shen Liu</a>, <a href="https://scholar.google.com/citations?user=knvEK4AAAAAJ&hl=en"> Tiejun Huang</a>, <a href="https://www.xloong.wang/">Xinlong Wang#</a>
                <br>
                <em>arXiv 2023.
                <br>
                <a href="https://mabaorui.github.io/GeoDream_page/">project page</a> |             
                <a href="https://arxiv.org/abs/2311.17971/">arXiv</a> |
                <a href="https://github.com/baaivision/GeoDream">code</a>
                <p align="justify", style="font-size:13px">We present GeoDream, a 3D generation method that incorporates explicit generalized 3D priors with 2D diffusion priors to enhance the capability of obtaining unambiguous 3D consistent geometric structures without sacrificing diversity or fidelity.
                </p>
            </td>
          </tr>



            <tr onmouseout="uni3d_stop()" onmouseover="uni3d_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id="uni3d" style="opacity: 0;">
                    <img src='image/uni3d_before.jpg' width="225">
                  </div>
                  <img src="image/uni3d_after.jpg" width="225">
        
                </div>
                <script type="text/javascript">
                  function uni3d_start() {
                    document.getElementById('uni3d').style.opacity = "1";
                  }
                  function uni3d_stop() {
                    document.getElementById('uni3d').style.opacity = "0";
                  }
                  uni3d_stop()
                </script>
              </td>
        
              <td width="65%" valign="top">
                <a href="https://github.com/baaivision/Uni3D">
                  <papertitle>Uni3D: Exploring Unified 3D Representation at Scale
                  </papertitle>
                </a>
                <br>
                <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, <a href="https://github.com/Wolfwjs/"> Jinsheng Wang*</a>, <strong> Baorui Ma*#</strong>, 
                <a href="https://yushen-liu.github.io/"> Yu-Shen Liu</a>, <a href="https://scholar.google.com/citations?user=knvEK4AAAAAJ&hl=en"> Tiejun Huang</a>, <a href="https://www.xloong.wang/">Xinlong Wang#</a>
                <br>
                <em>International Conference on Learning Representations <b>(ICLR, TH-CPL A)</b></em>, 2024  (<strong><span style="color:#ff0000;">Spotlight, ~5% acceptance rate</span></strong>)
                <br>
                <a href="https://huggingface.co/BAAI/Uni3D/tree/main/modelzoo">Model Zoo</a> |             
                <a href="https://arxiv.org/abs/2310.06773/">arXiv</a> |
                <a href="https://github.com/baaivision/Uni3D">code</a>
        
                <p align="justify", style="font-size:13px">We present Uni3D, a unified and scalable 3D pretraining framework for large-scale 3D representation learning, and explore its limits at the scale of one billion parameters.
                </p>
              </td>
            </tr>
  
            <tr onmouseout="VP2P_stop()" onmouseover="VP2P_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id="VP2P" style="opacity: 0;">
                    <video width="225" muted="" autoplay="" loop="">
                      <source src="image/Video_VP2PMatching_before.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <img src="image/Video_VP2PMatching_after.png" width="225">
        
                </div>
  
                <script type="text/javascript">
                  function VP2P_start() {
                    document.getElementById('VP2P').style.opacity = "1";
                  }
                  function VP2P_stop() {
                    document.getElementById('VP2P').style.opacity = "0";
                  }
                  VP2P_stop()
                </script>
              </td>
        
              <td width="65%" valign="top">
                <a href="">
                  <papertitle>Differentiable Registration of Images and LiDAR Point Clouds with VoxelPoint-to-Pixel Matching
                  </papertitle>
                </a>
                <br>
                <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, <strong> Baorui Ma*</strong>, Wenyuan Zhang, <a href="http://mmvc.engineering.nyu.edu/">Yi Fang</a>,
                <a href="https://yushen-liu.github.io/"> Yu-Shen Liu#</a>, <a href="https://h312h.github.io/">Zhizhong Han</a>
                <br>
                <em>Conference on Neural Information Processing Systems <b>(NeurIPS, CCF-A)</b></em>, 2023  (<strong><span style="color:#ff0000;">Spotlight, ~3.6% acceptance rate</span></strong>)
                <br>
                <a href="https://arxiv.org/abs/2312.04060">project page</a> |             
                <a href="https://arxiv.org/abs/2312.04060">arXiv</a> |
                <a href="https://github.com/junshengzhou/VP2P-Match">code</a>
              </td>
            </tr>


            <tr onmouseout="ICCVUDF_stop()" onmouseover="ICCVUDF_start()">
              <td width="25%">
                <div class="one">
                  <div class="two" id="ICCVUDF" style="opacity: 0;">
                    <img src='image/iccv23udf_before.gif' width="225">
                  </div>
                  <img src="image/iccv23udf_before.gif" width="225">
  
                </div>
                <script type="text/javascript">
                  function ICCVUDF_start() {
                    document.getElementById('ICCVUDF').style.opacity = "1";
                  }
                  function ICCVUDF_stop() {
                    document.getElementById('ICCVUDF').style.opacity = "0";
                  }
                  ICCVUDF_stop()
                </script>
              </td>
  
              <td width="65%" valign="top">
                <a href="https://github.com/junshengzhou/LevelSetUDF">
                  <papertitle>Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection
                  </papertitle>
                </a>
                <br>
                <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, <strong> Baorui Ma*</strong>, Shujuan Li, 
                <a href="https://yushen-liu.github.io/"> Yu-Shen Liu#</a>, <a href="https://h312h.github.io/">Zhizhong Han</a>
                <br>
                <em>IEEE/CVF International Conference on Computer Vision <b>(ICCV, CCF-A)</b></em>, 2023
                <br>
                <a href="https://github.com/junshengzhou/LevelSetUDF">project page</a> |             
                <a href="https://arxiv.org/abs/2308.11441/">arXiv</a> |
                <a href="https://github.com/junshengzhou/LevelSetUDF">code</a>
  
              </td>
            </tr>

          <tr onmouseout="noise_stop()" onmouseover="noise_start()">  
            <td width="25%">
              <div class="one">
              <div class="two" id = 'noise'>
              <img src='image/ParisZoom1.png' width="230" height="150"></div>
              <img src='image/ParisZoom1.png' width="230" height="150"></div>
              </div>
              <script type="text/javascript">
              function noise_start() { 
              document.getElementById('noise').style.opacity = "1";
              }
              function noise_stop() { 
              document.getElementById('noise').style.opacity = "0"; 
              }
              noise_stop()
              </script>
              </script>
            </td>
            <td valign="top" width="75%">
                <a href="https://github.com/mabaorui/Noise2NoiseMapping/">
                  <papertitle>
                    Learning Signed Distance Functions from Noisy 3D Point Clouds via Noise to Noise Mapping
                  </papertitle>
                </a>
            <br>
                <strong>Baorui Ma</strong>,
                <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>,
                <a href="https://h312h.github.io/">Zhizhong Han</a>
            <br>
            <em>International Conference on Machine Learning (<strong>ICML, CCF-A</strong>)</em>, 2023 <strong>(<span style="color:#ff0000;">Oral, ~2.3% acceptance rate</span>)</strong>
            <br>
              <a href="https://arxiv.org/abs/2306.01405/">paper</a> |
              <a href="https://github.com/mabaorui/Noise2NoiseMapping//">code</a>
            </td>
          </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
            <tr onmouseout="towards_stop()" onmouseover="towards_start()">  
              <td width="25%">
                <div class="one">
                <div class="two" id = 'towards'>
                <img src='image/towards.png' width="190" height="150"></div>
                <img src='image/towards.png' width="190" height="150"></div>
                </div>
                <script type="text/javascript">
                function towards_start() { 
                document.getElementById('towards').style.opacity = "1";
                }
                function towards_stop() { 
                document.getElementById('towards').style.opacity = "0"; 
                }
                towards_stop()
                </script>
                </script>
              </td>
              <td valign="top" width="75%">
                  <a href="http://arxiv.org/abs/2305.11601/">
                    <papertitle>
                      Towards Better Gradient Consistency for Neural Signed Distance Functions via Level Set Alignment
                    </papertitle>
                  </a>
              <br>
                  <strong>Baorui Ma*</strong>,
                  <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>,
                  <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>,
                  <a href="https://h312h.github.io/">Zhizhong Han</a>
              <br>
                  <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR, CCF-A</strong>)</em>, 2023
              <br>
                <a href="http://arxiv.org/abs/2305.11601/">paper</a> |
                <a href="https://github.com/mabaorui/TowardsBetterGradient/">project page</a> |
                <a href="https://github.com/mabaorui/TowardsBetterGradient/">code</a>
              </td>
            </tr>

          <tr onmouseout="NeAF_stop()" onmouseover="NeAF_start()">  
            <td width="25%">
              <div class="one">
              <div class="two" id = 'NeAF'>
              <img src='image/NeAF.png' width="230" height="150"></div>
              <img src='image/NeAF.png' width="230" height="150"></div>
              </div>
              <script type="text/javascript">
              function NeAF_start() { 
              document.getElementById('NeAF').style.opacity = "1";
              }
              function NeAF_stop() { 
              document.getElementById('NeAF').style.opacity = "0"; 
              }
              NeAF_stop()
              </script>
              </script>
            </td>
            <td valign="top" width="75%">
                <a href="https://arxiv.org/abs/2211.16869">
                  <papertitle>
                    NeAF: Learning Neural Angle Fields for Point Normal Estimation
                  </papertitle>
                </a>
            <br>
                <a href="https://lisj575.github.io/NeAF/">Shujuan Li*</a>,
                <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>
                <strong>Baorui Ma</strong>,
                <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>,
                <a href="https://h312h.github.io/">Zhizhong Han</a>
            <br>
                <em>AAAI Conference on Computing on Artificial Intelligence (<strong>AAAI, CCF-A</strong>)</em>, 2023 (<strong><span style="color:#ff0000;">Oral, ~10% acceptance rate</span></strong>)
            <br>
              <a href="https://arxiv.org/abs/2211.16869">paper</a> |
              <a href="https://lisj575.github.io/NeAF/">project page</a> |
              <a href="https://github.com/lisj575/NeAF/">code</a>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody>
          <tr onmouseout="capudf_stop()" onmouseover="capudf_start()">
            <td width="25%">
              <div class="one">
                <div class="two" id="capudf_shape" style="opacity: 0;">
                  <img src='image/capudf_before.png'  width="230" height="150">
                </div>
                <img src="image/capudf_after.png"  width="230" height="150">
              </div>
              <script type="text/javascript">
                function capudf_start() {
                  document.getElementById('capudf_shape').style.opacity = "1";
                }
                function capudf_stop() {
                  document.getElementById('capudf_shape').style.opacity = "0";
                }
                capudf_stop()
              </script>
            </td>

            <td width="75%" valign="top">
              <a href="https://junshengzhou.github.io/CAP-UDF/">
                <papertitle>Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds</papertitle>
              </a>
              <br>
              <a href="https://junshengzhou.github.io/"> Junsheng Zhou* </a>, <strong> Baorui Ma* </strong>, <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>, <a href="http://mmvc.engineering.nyu.edu/">Yi Fang</a>, <a href="https://h312h.github.io/">Zhizhong Han</a>
              <br>
              <em>Conference on Neural Information Processing Systems (<strong>NeurIPS, CCF-A</strong>)</em>, 2022 
              <br>
              <a href="https://arxiv.org/pdf/2210.02757.pdf">paper</a> |
              <a href="https://junshengzhou.github.io/CAP-UDF/">project page</a> |             
              <a href="https://github.com/junshengzhou/CAP-UDF">code</a>

              <p align="justify", style="font-size:13px">We present CAP-UDF to represent shapes and scenes with arbitrary architecture by learning a Consistency-Aware unsigned distance function Progressively.
              </p>
            </td>
          </tr>
          </tbody>
       </table>
    
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr onmouseout="OnSurPrior_stop()" onmouseover="OnSurPrior_start()">  
          <td width="25%">
            <div class="one">
            <div class="two" id = 'OnSurPrior'>
            <img src='image/OnSurPrior-plane.png' width="230" height="150"></div>
            <img src='image/OnSurPrior-plane.png' width="230" height="150"></div>
            </div>
            <script type="text/javascript">
            function OnSurPrior_start() { 
            document.getElementById('OnSurPrior').style.opacity = "1";
            }
            function OnSurPrior_stop() { 
            document.getElementById('OnSurPrior').style.opacity = "0"; 
            }
            OnSurPriorn_stop()
            </script>
            </script>
          </td>
          <td valign="top" width="75%">
              <a href="https://mabaorui.github.io/-OnSurfacePrior_project_page/">
                <papertitle>
                  Reconstructing Surfaces for Sparse Point Clouds with On-Surface Priors
                </papertitle>
              </a>
          <br>
              <strong>Baorui Ma</strong>,
              <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>,
              <a href="https://h312h.github.io/">Zhizhong Han</a>
          <br>
              <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR, CCF-A</strong>)</em>, 2022
          <br>
            <a href="https://arxiv.org/abs/2204.10603">paper</a> |
            <a href="https://mabaorui.github.io/-OnSurfacePrior_project_page/">project page</a> |
            <a href="https://github.com/mabaorui/OnSurfacePrior">code</a>
          </td>
        </tr>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
          <tr onmouseout="LocalPrior_stop()" onmouseover="LocalPrior_start()">  
            <td width="25%">
              <div class="one">
              <div class="two" id = 'LocalPrior'>
              <img src='image/Local-Teaser1.png' width="230" height="150"></div>
              <img src='image/Local-Teaser1.png' width="230" height="150"></div>
              </div>
              <script type="text/javascript">
              function LocalPrior_start() { 
              document.getElementById('LocalPrior').style.opacity = "1";
              }
              function LocalPrior_stop() { 
              document.getElementById('LocalPrior').style.opacity = "0"; 
              }
              LocalPrior_stop()
              </script>
              </script>
            </td>
            <td valign="top" width="75%">
                <a href="https://mabaorui.github.io/PredictableContextPrior_page/">
                  <papertitle>
                    Surface Reconstruction from Point Clouds by Learning Predictive Context Priors
                  </papertitle>
                </a>
            <br>
                <strong>Baorui Ma</strong>,
                <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>,
                <a href="https://www.cs.umd.edu/~zwicker/">Matthias Zwicker</a>
                <a href="https://h312h.github.io/">Zhizhong Han</a>
            <br>
                <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR, CCF-A</strong>)</em>, 2022
            <br>
              <a href="https://arxiv.org/abs/2204.11015">paper</a> |
              <a href="https://mabaorui.github.io/PredictableContextPrior_page/">project page</a> |
              <a href="https://github.com/mabaorui/PredictableContextPrior">code</a>
            </td>
          </tr>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
            <tr onmouseout="NP_stop()" onmouseover="NP_start()">  
              <td width="25%">
                <div class="one">
                <div class="two" id = 'NP'>
                <img src='image/NP-Overview.png' width="230" height="150"></div>
                <img src='image/NP-Overview.png' width="230" height="150"></div>
                </div>
                <script type="text/javascript">
                function NP_start() { 
                document.getElementById('NP').style.opacity = "1";
                }
                function NP_stop() { 
                document.getElementById('NP').style.opacity = "0"; 
                }
                NP_stop()
                </script>
                </script>
              </td>
              <td valign="top" width="75%">
                  <a href="https://github.com/mabaorui/NeuralPull">
                    <papertitle>
                      Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces
                    </papertitle>
                  </a>
              <br>
                  <strong>Baorui Ma*</strong>,
                  <a href="https://h312h.github.io/">Zhizhong Han*</a>
                  <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>,
                  <a href="https://www.cs.umd.edu/~zwicker/">Matthias Zwicker</a>
              <br>
                  <em>International Conference on Machine Learning (<strong>ICML, CCF-A</strong>)</em>, 2021 (<strong><span style="color:#ff0000;">Spotlight</span></strong>)
              <br>
                <!-- (* equal contribution) -->
                <br>
                <a href="https://arxiv.org/abs/2011.13495">paper</a> |
                <a href="https://github.com/mabaorui/NeuralPull">code</a>
              </td>
            </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
              <tr onmouseout="SKETCH_stop()" onmouseover="SKETCH_start()">  
                <td width="25%">
                  <div class="one">
                  <div class="two" id = 'SKETCH'>
                  <img src='image/reconstructing_tip2020.png' width="230" height="150"></div>
                  <img src='image/reconstructing_tip2020.png' width="230" height="150"></div>
                  </div>
                  <script type="text/javascript">
                  function SKETCH_start() { 
                  document.getElementById('SKETCH').style.opacity = "1";
                  }
                  function SKETCH_stop() { 
                  document.getElementById('SKETCH').style.opacity = "0"; 
                  }
                  SKETCH_stop()
                  </script>
                  </script>
                </td>
                <td valign="top" width="75%">
                    <a href="https://yushen-liu.github.io/main/pdf/LiuYS_TIP20Sketch3D.pdf">
                      <papertitle>
                        Reconstructing 3D Shapes from Multiple Sketches using Direct Shape Optimization
                      </papertitle>
                    </a>
                <br>
                    <a href="https://h312h.github.io/">Zhizhong Han</a>,
                    <strong>Baorui Ma</strong>,
                    <a href="https://www.cs.umd.edu/~zwicker/">Matthias Zwicker</a>,
                    <a href="https://yushen-liu.github.io/">Yu-Shen Liu#</a>
                <br>
                    <em>IEEE Transactions on Image Processing (SCI, Impact factor: 9.34) (<strong>TIP, CCF-A</strong>)</em>, 2020
                <br>
                  <a href="https://yushen-liu.github.io/main/pdf/LiuYS_TIP20Sketch3D.pdf">paper</a> |
                  <a href="https://yushen-liu.github.io/video_page/MS.mp4">Demo</a>
                </td>
              </tr>
  
  </table>
    

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <heading>Honors and Awards</heading>
          <tr>
            <td>
              
              <ul>
                  <li> Outstanding Graduate of Tsinghua University, Beijing (北京市优秀毕业生), 2023. <br>
                  <li> Doctoral National Scholarship, Tsinghua University (博士国家奖学金) (2 graduates per year in School of Software), 2022.<br>
              </ul>
            </td>
          </tr>
      </table>
  
      <!-- Academic Services -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <heading>Academic Services</heading>
          <tr>
            <td>
              
              <ul>
                  <li> <strong>Conference Reviewer</strong>: ICML, NeurIPS, CVPR, ICCV. <br>
              </ul>
            </td>
          </tr>
      </table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          template adapted from <a href="https://jonbarron.info/"><font size="2">this awesome website</font></a>
          <br>
          Last updated: Oct 2023
          <br>
          <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fmabaorui.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
        </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-116734954-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
      <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116734954-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-116734954-1');
</script>
    </td>
    </tr>
  </table>
  </body>
</html>
<!--  -->
